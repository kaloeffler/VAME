{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0729fc69",
   "metadata": {},
   "source": [
    "## Embed multiple rats in the same latent space\n",
    "\n",
    "Motivation: if the learned embeddings are more or less indepenend from the rat, embeddings from different rats shouldn't be embedded\n",
    "in different parts of the latent space - appart from extreme behavior which are occuring only in a single rat e.g. seisures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3513eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/home/katharina/vame_approach/VAME\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from vame.analysis.kinutils import KinVideo, create_grid_video\n",
    "import os\n",
    "from datetime import datetime\n",
    "from vame.util.auxiliary import read_config\n",
    "import logging\n",
    "import re\n",
    "from pathlib import Path\n",
    "from IPython import display\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from fcmeans import FCM\n",
    "from ipywidgets import Output, GridspecLayout\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from vame.analysis.utils import (\n",
    "    create_aligned_mouse_video,\n",
    "    create_pose_snipplet,\n",
    "    create_visual_comparison,\n",
    "    thin_dataset_iteratively,\n",
    "    find_percentile_threshold,\n",
    "    estimate_fuzzifier,\n",
    "    fukuyama_sugeno_index,\n",
    ")\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from vame.initialize_project.themis_new import get_video_metadata\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2cc125",
   "metadata": {},
   "source": [
    "## 1) Load latent vectors predicted from different videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"/home/katharina/vame_approach/tb_align_0044_0089\"\n",
    "PROJECT_PATH = \"/home/katharina/vame_approach/themis_tail_belly_align\"\n",
    "PROJECT_PATH = \"/home/katharina/vame_approach/tb_align_0089\"\n",
    "\n",
    "trained_models = [\n",
    "    (datetime.strptime(element, \"%m-%d-%Y-%H-%M\"), element)\n",
    "    for element in os.listdir(os.path.join(PROJECT_PATH, \"model\"))\n",
    "]\n",
    "# sort by time step\n",
    "trained_models.sort(key=lambda x: x[0])\n",
    "latest_model = trained_models[-1][-1]\n",
    "\n",
    "config_file = os.path.join(PROJECT_PATH, \"model\", latest_model, \"config.yaml\")\n",
    "config = read_config(config_file)\n",
    "\n",
    "latent_vec_dir = os.path.join(PROJECT_PATH, \"inference\", \"results\", latest_model)\n",
    "latent_vec_files = [\n",
    "    os.path.join(latent_vec_dir, file) for file in os.listdir(latent_vec_dir)\n",
    "]\n",
    "latent_vectors = {\n",
    "    os.path.basename(file).split(\"_\")[3]: np.load(file) for file in latent_vec_files\n",
    "}\n",
    "\n",
    "# use only 0089, 0088, 0087 - all from H06\n",
    "# latent_vectors = {k: v for k, v in latent_vectors.items() if k in [\"0087\", \"0088\", \"0089\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent_vectors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e67ee",
   "metadata": {},
   "source": [
    "## 2) Data Dilution\n",
    "Dilute each set of latent vectors sepeately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilute the datasets\n",
    "neighbor_percentiles = {}\n",
    "latent_vectors_diluted = {}\n",
    "time_ids_diluted = {}\n",
    "sub_sampling_factor = (\n",
    "    config[\"time_window\"] // 10\n",
    ")  # choose a subsampling factor for neighbor percentile estimation to save memory\n",
    "for video_id, latent_vec in latent_vectors.items():\n",
    "    neighbor_percentiles[video_id] = find_percentile_threshold(\n",
    "        latent_vec[::sub_sampling_factor],\n",
    "        config[\"time_window\"],\n",
    "        time_idx=np.arange(0, len(latent_vec))[::sub_sampling_factor],\n",
    "        test_fraction=0.01 * sub_sampling_factor,\n",
    "    )\n",
    "    remaining_embeddings, remaining_time_ids = thin_dataset_iteratively(\n",
    "        latent_vec, 0.00001, neighbor_percentiles[video_id], config[\"time_window\"]\n",
    "    )\n",
    "\n",
    "    latent_vectors_diluted[video_id] = remaining_embeddings\n",
    "    time_ids_diluted[video_id] = remaining_time_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7d63c",
   "metadata": {},
   "source": [
    "## 3) Visualize Diluted Data\n",
    "Ideally the learned latent space should embed the same behavior, indepentend of the actual specimen, to the same place\n",
    "in the latent space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, all_latent_vectors = list(\n",
    "    zip(*[(k, v) for k, v in latent_vectors_diluted.items()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd495e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_full = [[l] * len(latent_vectors_diluted[l]) for l in labels]\n",
    "labels_full = np.array([l for sub_list in labels_full for l in sub_list])\n",
    "all_latent_vectors = np.concatenate(all_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_trafo = umap.UMAP(\n",
    "    n_components=2, min_dist=0.001, n_neighbors=30, random_state=config[\"random_state\"]\n",
    ").fit(all_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a606f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rat id based on the video id\n",
    "video_info_file = os.path.join(PROJECT_PATH, \"video_info.csv\")\n",
    "video_info = pd.read_csv(video_info_file)\n",
    "video_id_rat_id = {\n",
    "    l: video_info[video_info[\"vid_file\"] == l + \".MP4\"][\"rat\"].values[0] for l in labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05649af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "print(all_latent_vectors.shape)\n",
    "umap_embeddings = umap_trafo.transform(all_latent_vectors)\n",
    "\n",
    "cmap = cm.get_cmap(\"rainbow\", len(labels))\n",
    "for l in labels:\n",
    "    print(l)\n",
    "    plt.scatter(\n",
    "        umap_embeddings[labels_full == l, 0],\n",
    "        umap_embeddings[labels_full == l, 1],\n",
    "        color=cmap(labels.index(l)),\n",
    "        edgecolor=\"k\",\n",
    "        label=l,\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46253fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from numpy import linalg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_vectors = pca.fit_transform(all_latent_vectors)\n",
    "# set colour map so each ellipsoid as a unique colour\n",
    "norm = colors.Normalize(vmin=0, vmax=len(labels))\n",
    "cmap = cm.get_cmap(\"tab10\", len(labels))\n",
    "m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "cluster_means = [\n",
    "    np.mean(pca_vectors[labels_full == i_cluster], axis=0) for i_cluster in labels\n",
    "]\n",
    "cluster_cov = [np.cov(pca_vectors[labels_full == i_cluster].T) for i_cluster in labels]\n",
    "\n",
    "for i_cluster, label in enumerate(labels):\n",
    "    # your ellispsoid and center in matrix form\n",
    "\n",
    "    center = cluster_means[i_cluster]\n",
    "    A = cluster_cov[i_cluster]\n",
    "    # calc eigenvalues (the srt is the radius) and the eigenvectors (rotation) of the ellipsoid!\n",
    "    eigen_vals, eigen_vec = linalg.eig(A)\n",
    "    radii = np.sqrt(eigen_vals)\n",
    "\n",
    "    # calculate cartesian coordinates for the ellipsoid surface\n",
    "    u = np.linspace(0.0, 2.0 * np.pi, 60)\n",
    "    v = np.linspace(0.0, np.pi, 60)\n",
    "    x = radii[0] * np.outer(np.cos(u), np.sin(v))\n",
    "    y = radii[1] * np.outer(np.sin(u), np.sin(v))\n",
    "    z = radii[2] * np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x)):\n",
    "            [x[i, j], y[i, j], z[i, j]] = (\n",
    "                np.dot(eigen_vec, [x[i, j], y[i, j], z[i, j]]) + center\n",
    "            )\n",
    "    # ax.plot_surface(\n",
    "    #    x,\n",
    "    #    y,\n",
    "    #    z,\n",
    "    #    rstride=3,\n",
    "    #    cstride=3,\n",
    "    #    color=m.to_rgba(i_cluster),\n",
    "    #    linewidth=0.1,\n",
    "    #    alpha=0.3,\n",
    "    #    shade=True,\n",
    "    #    label=label_name,\n",
    "    # )\n",
    "    ax.plot(\n",
    "        pca_vectors[labels_full == label, 0],\n",
    "        pca_vectors[labels_full == label, 1],\n",
    "        pca_vectors[labels_full == label, 2],\n",
    "        \".\",\n",
    "        color=m.to_rgba(i_cluster),\n",
    "        alpha=0.5,\n",
    "        label=\":\".join([video_id_rat_id[label], label]),\n",
    "    )\n",
    "\n",
    "min_val = np.amin(pca_vectors)  # lowest number in the array\n",
    "max_val = np.amax(pca_vectors)  # highest number in the array\n",
    "\n",
    "ax.set_xlim3d(min_val, max_val)\n",
    "ax.set_ylim3d(min_val, max_val)\n",
    "ax.set_zlim3d(min_val, max_val)\n",
    "ax.legend()\n",
    "\n",
    "# K8 (videos 0056 and 0053) has actually seizures and a very different behavior to the other rats\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b65099",
   "metadata": {},
   "source": [
    "## Clustering with DBSCAN based on a reduced number of feature dimensions using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b80b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dim_red = PCA(n_components=20)\n",
    "pca_dim_red.fit(all_latent_vectors)\n",
    "print(\n",
    "    f\"Explained variance cumulated over the dimensions: {pca_dim_red.explained_variance_ratio_.cumsum()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_latent_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "pca_vectors = pca.fit_transform(all_latent_vectors)\n",
    "dbscan = DBSCAN(eps=1.0, min_samples=10)\n",
    "\n",
    "dbscan_labels = dbscan.fit_predict(pca_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ada72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Num labels:\",\n",
    "    np.max(dbscan_labels) + 1,\n",
    "    \", Outlier percentage:\",\n",
    "    np.round(sum(dbscan_labels == -1) / len(dbscan_labels) * 100, 2),\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46467201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print per cluster number of assigned samples / fraction of samples from one rat total / relative\n",
    "for i_cluster in range(np.max(dbscan_labels)):\n",
    "    print(f\"Cluster: {i_cluster}\")\n",
    "    print(\n",
    "        f\"Assigned samples: {np.sum(dbscan_labels == i_cluster)} / {len(dbscan_labels)}; percentage {np.round(np.sum(dbscan_labels == i_cluster) / len(dbscan_labels) * 100,2)}%\"\n",
    "    )\n",
    "    samples_per_video = [\n",
    "        (l, np.sum(labels_full[dbscan_labels == i_cluster] == l)) for l in labels\n",
    "    ]\n",
    "    print(f\"Total samples per video: {samples_per_video}\")\n",
    "    samples_per_video = [\n",
    "        (\n",
    "            l,\n",
    "            str(\n",
    "                np.round(\n",
    "                    np.sum(labels_full[dbscan_labels == i_cluster] == l)\n",
    "                    / np.sum(labels_full == l)\n",
    "                    * 100\n",
    "                )\n",
    "            )\n",
    "            + \"%\",\n",
    "        )\n",
    "        for l in labels\n",
    "    ]\n",
    "    print(f\"samples rel. to video length: {samples_per_video}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e11535",
   "metadata": {},
   "source": [
    "### Observation: Many of the found clusters with DBSCAN are extremely small (eps. ~2.3; min_samples=5), whereas the biggest cluster contains ~85% of all samples. Decreasing the eps or increasing the number of samples just increases the fraction of outliers and results in tiny clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f04cc0",
   "metadata": {},
   "source": [
    "## Clustering with Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_fcm = 50\n",
    "fcm = FCM(n_clusters=n_clusters_fcm, m=1.1)\n",
    "\n",
    "# cluster the data in fewer dimensions\n",
    "fcm.fit(pca_vectors)\n",
    "\n",
    "# output\n",
    "fcm_centers = fcm.centers\n",
    "# output is [N,K]: N number of latent embeddings and K the number of clusters; for where each entry is a membership score between 0...1\n",
    "fcm_labels_soft = fcm.soft_predict(pca_vectors)\n",
    "fcm_labels = np.argmax(fcm_labels_soft, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark samples below a certain membership thr as outliers\n",
    "min_membership_thr = 0.7\n",
    "fcm_labels[np.max(fcm_labels_soft, axis=1) < min_membership_thr] = -1\n",
    "print(f\"Samples assigned to outlier group: {np.sum(fcm_labels == -1)} / {len(fcm_labels)}; percentage {np.round(100 * np.sum(fcm_labels == -1) / len(fcm_labels),2)}%\")\n",
    "# plot num samples assigned to outliers per video\n",
    "for l in labels:\n",
    "    num_outliers = np.sum(fcm_labels[labels_full == l] == -1)\n",
    "    print(f\"Video: {l}, Rat:{video_id_rat_id[l]}\")\n",
    "    print(f\"Num Outliers {num_outliers} / {np.sum(labels_full==l)}; Percentage {num_outliers / np.sum(labels_full==l) * 100}%\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a087552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print per cluster number of assigned samples / fraction of samples from one rat total / relative\n",
    "for i_cluster in range(np.max(n_clusters_fcm)):\n",
    "    print(f\"Cluster: {i_cluster}\")\n",
    "    print(\n",
    "        f\"Assigned samples: {np.sum(fcm_labels == i_cluster)} / {len(fcm_labels)}; percentage {np.round(100 * np.sum(fcm_labels == i_cluster) / len(fcm_labels),2)}%\"\n",
    "    )\n",
    "    samples_per_video = [\n",
    "        (l, np.sum(labels_full[fcm_labels == i_cluster] == l)) for l in labels\n",
    "    ]\n",
    "    print(f\"Total samples per video: {samples_per_video}\")\n",
    "    samples_per_video = [\n",
    "        (\n",
    "            l,\n",
    "            str(\n",
    "                np.round(\n",
    "                    np.sum(labels_full[fcm_labels == i_cluster] == l)\n",
    "                    / np.sum(labels_full == l)\n",
    "                    * 100\n",
    "                )\n",
    "            )\n",
    "            + \"%\",\n",
    "        )\n",
    "        for l in labels\n",
    "    ]\n",
    "    print(f\"samples rel. to video length: {samples_per_video}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7650ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = [\"0087\", \"0088\", \"0089\"]\n",
    "\n",
    "is_in_sub_set = np.isin(labels_full, sub_set)\n",
    "is_in_sub_set[:] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridspecLayout(int(np.ceil(n_clusters_fcm /2.0)), 2)\n",
    "# sorted video files\n",
    "aligned_video_files = {\n",
    "    l: os.path.join(PROJECT_PATH, \"videos\", \"aligned_videos\", \"a\" + l + \".MP4\")\n",
    "    for l in labels\n",
    "}\n",
    "time_idx_stacked = np.concatenate([time_ids_diluted[l] for l in labels])\n",
    "\n",
    "\n",
    "video = KinVideo(aligned_video_files[sub_set[0]], view=\"Down\")\n",
    "video.probevid()\n",
    "video_clip_duration = config[\"time_window\"] / video.getfps()\n",
    "\n",
    "\n",
    "for i_cluster_id in range(n_clusters_fcm):\n",
    "\n",
    "    sampled_idx = np.random.choice(\n",
    "        np.arange(0, len(fcm_labels))[\n",
    "            (fcm_labels == i_cluster_id) & is_in_sub_set\n",
    "        ],\n",
    "        min(16, np.sum((fcm_labels == i_cluster_id) & is_in_sub_set)),\n",
    "        replace=False,\n",
    "    )\n",
    "    if len(sampled_idx) > 0:\n",
    "        video_clip_data_cluster = [\n",
    "            (\n",
    "                aligned_video_files[labels_full[idx]],\n",
    "                time_idx_stacked[idx] / video.getfps(),\n",
    "                (0, 0, video.width, video.height),\n",
    "            )\n",
    "            for idx in sampled_idx\n",
    "        ]\n",
    "        grid_video_cluster = create_grid_video(\n",
    "            video_clip_data_cluster, video_clip_duration, speed=0.5, nrows=4, ncols=4,\n",
    "        )\n",
    "        out = Output()\n",
    "        with out:\n",
    "            display.display(\n",
    "                display.Video(\n",
    "                    grid_video_cluster,\n",
    "                    embed=True,\n",
    "                    html_attributes=\"loop autoplay\",\n",
    "                    width=450,\n",
    "                    height=450,\n",
    "                )\n",
    "            )\n",
    "        if i_cluster_id % 2 == 0:\n",
    "            idx_col = 0\n",
    "        else:\n",
    "            idx_col = 1\n",
    "        grid[i_cluster_id // 2, idx_col] = out\n",
    "\n",
    "# just h\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad790d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv_VAME] *",
   "language": "python",
   "name": "conda-env-venv_VAME-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
