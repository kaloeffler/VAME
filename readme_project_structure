Project structure of the VAME project:

analysis:
    community_analysis.py:
        calculate transition probabilities between subsequent motifs
        convert markov chain to tree for community detection??
        func for umap embedding and visualization
    generative_functions.py:
        sampling from the latent space - then generate image from this sample
        visualization of the cluster center
        generative model func: load different latent vectors
    gif_creator.py:
        create the gif video

    pose_segmentation.py:
        embed latent vector - -PE-seq-clean.npy
        -> load file get a sequence and encode it then use encoding, forward to lambda and get mean? representation
        get counts of motif usage per video
        the actual pose segmentation is predicting the latent vectors (so encode with encoder, forward encoding to latent space - get mean?? from latent space); then kMeans clustering
        (almost ally .npy filses are generated here: km_label; cluster_center, latent_vector, motif_usage)
    segment_behavior.py:
        different clustering approaches GMM; kMeans
        predict latent space - so forwarding everything to the encoder/lambda opart of the model; then cluster everyting (km_label.npy, latent_vector.npy files)

    tree_hierarchy.py:
        hierachy of motifs; convert transition graph to tree hierarchy of motifs?

    umap_visualization.py:
        visualize labels; communities; embeddings

    videowriter.py:
        create videos for motifs or for community

initialize project:
    new.py: create a folder structure for a new project (video, data, results, model) and create a config file

model:
    create_training.py:
        training data preparation: mean and std normalization per landmark file
        calc iqr (if robust flag in config is st) (interquantile range: difference between 75th and 25th percentile)
        mark values with nan that are outside the N*iqr - than interpolate values there
        FIXME: all files are stacked to one training sequence
        remove the two landmarks with the biggest std???
        savgol filter: smooth data (landmark evolution over time)
    
    dataloader.py:
        calc mean and std of already mean and std normalized dataset ??
    
    rnn_vae.py:
        define loss parts: KL-loss; "forecasting loss": MSE loss; "cluster loss": calc gram matrix then SVD (singluar value decomposition) - sum up the sqrt root of the SV's, "reconstruction loss": MSE loss

        KL annealing: motivation first learn data reconstruction for n steps before adding the KL loss term - so basically increase the weight on the KL loss over time

        training function: add noise (as augmentation?)
        load hyperparameters and set a seed for training
    
    rnn_model.py:
        implementation of the VAE approach; use of GRUs (gated recurrent units)
util:
    align_egocentrical.py:
        rotate and crop images such that landmarks are better aligned;
        interpolation of nan values
        background calculation
        play alined video function!!
    auxiliary.py:
        create config template
    csv_to_npy.py:
        for a priori egocentric datasets
    gif_pose_helper.py.
        image rotating; background substraction
